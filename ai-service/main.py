"""
AI Ingredient Detection Service
Fast, local ingredient detection using Salesforce BLIP model
"""
import io
import logging
import re
from typing import List, Dict, Any, Set
from PIL import Image
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
import uvicorn

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="AI Ingredient Detection Service",
    description="Local AI service for detecting ingredients from images",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

processor = None
model = None
device = None


def load_model():
    """Load the Salesforce BLIP model on startup"""
    global processor, model, device
    
    try:
        logger.info("Loading Salesforce BLIP model...")
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"Using device: {device}")
        
        model_name = "Salesforce/blip-image-captioning-base"
        processor = BlipProcessor.from_pretrained(model_name)
        model = BlipForConditionalGeneration.from_pretrained(model_name).to(device)
        
        logger.info("Model loaded successfully!")
    except Exception as e:
        logger.error(f"Failed to load model: {str(e)}", exc_info=True)
        raise


def extract_ingredients_from_caption(caption: str) -> List[str]:
    """
    Extract individual ingredients from the generated caption
    
    Args:
        caption: Image caption generated by BLIP model
    
    Returns:
        List of detected ingredients
    """
    # Common food-related stop words to filter out
    stop_words = {
        'a', 'an', 'the', 'and', 'or', 'of', 'in', 'on', 'with', 'at', 'to',
        'photo', 'picture', 'image', 'plate', 'bowl', 'table', 'dish', 'food',
        'kitchen', 'counter', 'cutting', 'board', 'wooden', 'white', 'black',
        'fresh', 'some', 'many', 'few', 'several', 'various', 'different'
    }
    
    # Common ingredient patterns and their normalized forms
    ingredient_mapping = {
        'tomato': ['tomato', 'tomatoes'],
        'onion': ['onion', 'onions'],
        'garlic': ['garlic'],
        'potato': ['potato', 'potatoes'],
        'carrot': ['carrot', 'carrots'],
        'pepper': ['pepper', 'peppers', 'bell pepper'],
        'chili': ['chili', 'chilis', 'chilli'],
        'ginger': ['ginger'],
        'lettuce': ['lettuce'],
        'cabbage': ['cabbage'],
        'spinach': ['spinach'],
        'mushroom': ['mushroom', 'mushrooms'],
        'broccoli': ['broccoli'],
        'cauliflower': ['cauliflower'],
        'cucumber': ['cucumber', 'cucumbers'],
        'zucchini': ['zucchini'],
        'eggplant': ['eggplant', 'eggplants', 'aubergine'],
        'chicken': ['chicken'],
        'beef': ['beef'],
        'pork': ['pork'],
        'fish': ['fish'],
        'shrimp': ['shrimp', 'prawns'],
        'egg': ['egg', 'eggs'],
        'cheese': ['cheese'],
        'milk': ['milk'],
        'butter': ['butter'],
        'rice': ['rice'],
        'pasta': ['pasta'],
        'bread': ['bread'],
        'flour': ['flour'],
        'oil': ['oil'],
        'salt': ['salt'],
        'sugar': ['sugar'],
        'lemon': ['lemon', 'lemons'],
        'lime': ['lime', 'limes'],
        'apple': ['apple', 'apples'],
        'banana': ['banana', 'bananas'],
        'orange': ['orange', 'oranges'],
        'avocado': ['avocado', 'avocados'],
        'corn': ['corn'],
        'bean': ['bean', 'beans'],
        'pea': ['pea', 'peas'],
        'basil': ['basil'],
        'parsley': ['parsley'],
        'cilantro': ['cilantro', 'coriander'],
        'mint': ['mint'],
        'thyme': ['thyme'],
        'rosemary': ['rosemary'],
    }
    
    # Clean and tokenize caption
    caption_lower = caption.lower()
    # Remove punctuation and split
    words = re.findall(r'\b[a-z]+\b', caption_lower)
    
    detected_ingredients: Set[str] = set()
    
    # Check for ingredient patterns
    for base_ingredient, variants in ingredient_mapping.items():
        for variant in variants:
            if variant in caption_lower:
                detected_ingredients.add(base_ingredient)
                break
    
    # If no ingredients found using mapping, try extracting nouns
    if not detected_ingredients:
        for word in words:
            if word not in stop_words and len(word) > 3:
                detected_ingredients.add(word)
    
    return sorted(list(detected_ingredients))


@app.on_event("startup")
async def startup_event():
    """Load model when server starts"""
    load_model()


@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "service": "AI Ingredient Detection",
        "status": "running",
        "model": "Salesforce/blip-image-captioning-base",
        "device": str(device)
    }


@app.get("/health")
async def health():
    """Detailed health check"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "processor_loaded": processor is not None,
        "device": str(device)
    }


@app.post("/detect")
@app.post("/detect-ingredients")
async def detect_ingredients(file: UploadFile = File(...)):
    """
    Detect ingredients from an uploaded image
    
    Args:
        file: Uploaded image file (JPEG, PNG, etc.)
    
    Returns:
        JSON with detected ingredients list, caption, and confidence
    """
    try:
        logger.info(f"Received request - filename: {file.filename}, content_type: {file.content_type}")
        
        if model is None or processor is None:
            logger.error("Model not loaded!")
            raise HTTPException(
                status_code=503,
                detail="Model is still loading. Please wait a moment and try again."
            )
        
        if not file.content_type or not file.content_type.startswith('image/'):
            raise HTTPException(
                status_code=400,
                detail=f"Invalid file type: {file.content_type}. Must be an image."
            )
        
        logger.info(f"Processing image: {file.filename}")
        contents = await file.read()
        logger.info(f"Read {len(contents)} bytes")
        
        if len(contents) == 0:
            raise HTTPException(
                status_code=400,
                detail="Empty image file received."
            )
        
        logger.info("Opening image...")
        image = Image.open(io.BytesIO(contents)).convert('RGB')
        logger.info(f"Image opened successfully - size: {image.size}")
        
        logger.info("Processing with BLIP model...")
        inputs = processor(image, return_tensors="pt").to(device)
        
        logger.info("Generating caption...")
        with torch.no_grad():
            out = model.generate(**inputs, max_length=50)
        
        caption = processor.decode(out[0], skip_special_tokens=True)
        logger.info(f"Generated caption: {caption}")
        
        # Extract ingredients from caption
        logger.info("Extracting ingredients...")
        ingredients = extract_ingredients_from_caption(caption)
        logger.info(f"Extracted ingredients: {ingredients}")
        
        confidence = 0.85 if len(caption.split()) > 3 else 0.7
        
        response = {
            "success": True,
            "ingredients": ingredients,
            "caption": caption,
            "confidence": confidence,
            "model": "Salesforce/blip-image-captioning-base",
            "device": str(device)
        }
        
        logger.info(f"Successfully processed image with {len(ingredients)} ingredients")
        return response
        
    except HTTPException as he:
        logger.error(f"HTTP Exception: {he.detail}")
        raise
    except Exception as e:
        error_msg = f"{type(e).__name__}: {str(e)}"
        logger.error(f"Error processing image: {error_msg}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Error processing image: {error_msg}"
        )


@app.post("/detect-batch")
async def detect_ingredients_batch(files: List[UploadFile] = File(...)):
    """
    Detect ingredients from multiple images
    
    Args:
        files: List of uploaded image files
    
    Returns:
        JSON with results for each image
    """
    results = []
    
    for file in files:
        try:
            result = await detect_ingredients(file)
            results.append({
                "filename": file.filename,
                "result": result
            })
        except Exception as e:
            results.append({
                "filename": file.filename,
                "error": str(e)
            })
    
    return {
        "success": True,
        "count": len(results),
        "results": results
    }


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )
